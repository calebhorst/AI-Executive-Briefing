## Ethics and Responsible AI
```
There's a growing awareness and concern about the impact and the risks of A I particularly as we're very quickly relying more and more on these systems and some of the consequences are direct. Some of them are indirect and unintentional but still significant. An often unintentional side effect is algorithmic bias. An example is where machine learning was used to streamline recruitment and hiring at a large tech company to try and recognize and classify good candidates more quickly. And the model was trained on 10 years of actual resumes and real data about the qualities of previous successful candidates. But in a field like computing, which is historically skewed towards more male candidates just on pure numbers alone. Most successful candidates over the last 10 years had been men and that became part of what the machine learning model would then look for. That's what we trained it to learn. What does a successful candidate look like? Well, according to the data, it looks like a man. So does this new candidate match that description? No, well, then score them lower. So even when there was no intentional human prejudice involved, just in this case, the nature of a male heavy profession, a machine learning model can end up reinforcing that inequality. And figuring out this is even happening can be very difficult because one of the very real issues with many algorithms in machine learning is that when you train a model, what you get from it after that is an answer. What you don't get is an explanation of that answer. This is sometimes called the black box of A I or the black box of machine learning. You train the model with existing data, you then feed new data into the model and you get a result. Candidate A is rated five out of five, candidate B is rated two out of five. Why? Well, it doesn't tell you why because the algorithm was designed to provide a result. It wasn't designed to provide an explanation. And if you have an unquestioning culture of, well, that's what the computer says, then you could end up reinforcing biases in the system, even building a stronger bias system without realizing it. In addition, there's the issue of accountability because it can be genuinely difficult to figure out who's responsible if an A I generated product gives a wrong decision. Now, in some use cases, there's now a move towards what's called explainable A I or interpretable A I, which is where you would choose A I techniques that do not use that Black box approach. And they provide a human readable explanation of results in some governance and regulatory policies like the E US GDPR, they're starting to include the idea of a right to explanation. So in a situation like a credit being refused or a job application being rejected by an automated system, the system must then provide an explanation and accountability of it. And we also have techniques like deep fix where A I is used for intentional deception and misinformation. A deep fake usually refers to a video but it can also be just an image or an audio recording. But where A I is used to either replace a person or make it seem like they said something that they didn't and deep fakes are typically made using a form of generative A I. They're using these deep neural networks to create extremely realistic results. And because of these and there are plenty of other situations, there are now various initiatives around ethics in artificial intelligence and this idea of responsible A I. Now these days, most major tech organizations just as they share their annual reports or their information about sustainability efforts, they also provide explicit information about their A I ethics and principles often including at least information around how do we work with data privacy? How do we avoid bias and what do we do with transparency and explain ability and standards. Organizations like the I TRIPLE E have their global initiative on ethics of autonomous and intelligent systems. There's groups like partnership on A I with over 100 member organizations including Apple Microsoft Amazon, Google Accenture, all trying to develop guidelines and best practices about safety and transparency in artificial intelligence. And this idea of ethical and safe behavior in A I is part of the state ad mission of those organizations that are trying to develop artificial general intelligence or A G I because there is an understanding, it's incredibly important and it's not just going to happen by itself. We've seen a lot of A I researchers, tech leaders, scientists, all raising serious concerns about what's likely to happen if we're not thinking about how to create ethical and responsible A I well in advance or as Professor Stephen Hawking once said success in creating A I would be the biggest event in human history. Unfortunately, it might also be the last interesting times ahead. Hope you enjoyed the course. I'll see you next time.
```

## Notes
- **Algorithmic Bias:** Machine learning models trained on biased historical data can perpetuate inequalities unintentionally, like in recruitment models favoring male candidates in male-skewed professions.
- **Black Box Problem:** Many machine learning algorithms lack explanatory capabilities, providing results without explanations, leading to challenges in understanding decision-making processes.
- **Explainable AI (XAI):** In response to the black box issue, there's a move towards AI models that offer transparent and understandable outcomes, ensuring accountability and adherence to regulations like the EU's GDPR.
- **Deepfakes:** These realistic synthetic media created by AI, particularly generative AI, raise concerns about deceptive content creation, impacting trust and authenticity.
- **Ethics in AI:** Growing initiatives and organizations focus on ethical AI development, emphasizing responsible AI practices to address issues like bias, transparency, and accountability.
- **Organizational Efforts:** Major tech organizations are increasingly highlighting their AI ethics and principles, addressing data privacy, bias mitigation, transparency, and safety.
- **Initiatives and Partnerships:** Groups like IEEE and Partnership on AI, involving numerous tech giants, aim to establish guidelines and best practices for safe and transparent AI development.
- **Ethical Concerns for AGI:** The pursuit of Artificial General Intelligence (AGI) underscores the critical need for ethical considerations, recognizing the potential magnitude of AI's impact on humanity.
